# =============================================================================
# Internal AI Advisory Assistant - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# NEVER commit .env to version control
# =============================================================================

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
APP_NAME=internal-ai-advisory-assistant
APP_ENV=development  # development, staging, production
DEBUG=true
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR

# -----------------------------------------------------------------------------
# API Configuration
# -----------------------------------------------------------------------------
API_HOST=0.0.0.0
API_PORT=8000
API_PREFIX=/api/v1

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# -----------------------------------------------------------------------------
# Authentication
# -----------------------------------------------------------------------------
# In production, integrate with your identity provider (Okta, Azure AD, etc.)
# For development, we use simple API key + role header simulation
AUTH_ENABLED=true
API_KEY=your-development-api-key-change-in-production

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
# OpenAI-compatible API (works with OpenAI, Azure OpenAI, local models via vLLM)
LLM_PROVIDER=openai  # openai, azure, local
OPENAI_API_KEY=sk-your-api-key-here

# For Azure OpenAI
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_API_KEY=your-azure-key
# AZURE_OPENAI_DEPLOYMENT=gpt-4

# Model Selection
LLM_MODEL=gpt-4-turbo-preview
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2048
LLM_TIMEOUT=60  # seconds

# -----------------------------------------------------------------------------
# Embedding Configuration
# -----------------------------------------------------------------------------
EMBEDDING_PROVIDER=openai  # openai, sentence-transformers
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# For local embeddings (sentence-transformers)
# EMBEDDING_MODEL=all-MiniLM-L6-v2
# EMBEDDING_DIMENSION=384

# -----------------------------------------------------------------------------
# Vector Database Configuration
# -----------------------------------------------------------------------------
VECTOR_DB_PROVIDER=qdrant  # qdrant, faiss (faiss is local-only)

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=advisory_documents

# For Qdrant Cloud
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your-qdrant-api-key

# Local Qdrant storage path (for development)
QDRANT_PATH=./data/vector_store

# -----------------------------------------------------------------------------
# Retrieval Configuration
# -----------------------------------------------------------------------------
RETRIEVAL_TOP_K=10  # Number of documents to retrieve
RETRIEVAL_MIN_SCORE=0.5  # Minimum similarity score threshold

# Hybrid Search Settings
HYBRID_ENABLED=true
HYBRID_DENSE_WEIGHT=0.7  # Weight for vector search (0-1)
HYBRID_SPARSE_WEIGHT=0.3  # Weight for BM25 search (0-1)
RRF_K=60  # Reciprocal Rank Fusion constant

# -----------------------------------------------------------------------------
# Document Processing
# -----------------------------------------------------------------------------
CHUNK_SIZE=512  # Target chunk size in tokens
CHUNK_OVERLAP=64  # Overlap between chunks in tokens
MIN_CHUNK_SIZE=100  # Minimum chunk size to keep

# Supported file extensions
SUPPORTED_EXTENSIONS=.pdf,.docx,.md,.txt

# -----------------------------------------------------------------------------
# Data Paths
# -----------------------------------------------------------------------------
DATA_RAW_PATH=./data/raw
DATA_PROCESSED_PATH=./data/processed
FEEDBACK_DB_PATH=./data/feedback.db

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100  # Requests per window
RATE_LIMIT_WINDOW=60  # Window in seconds

# -----------------------------------------------------------------------------
# Observability
# -----------------------------------------------------------------------------
# Structured Logging
LOG_FORMAT=json  # json, console

# Metrics (optional - for production monitoring)
# METRICS_ENABLED=true
# METRICS_PORT=9090

# Tracing (optional - OpenTelemetry)
# OTEL_ENABLED=true
# OTEL_ENDPOINT=http://localhost:4317
# OTEL_SERVICE_NAME=advisory-assistant

# -----------------------------------------------------------------------------
# Feature Flags
# -----------------------------------------------------------------------------
FEATURE_FEEDBACK_ENABLED=true
FEATURE_INTENT_DETECTION_ENABLED=true
FEATURE_STRUCTURED_OUTPUT_ENABLED=true
